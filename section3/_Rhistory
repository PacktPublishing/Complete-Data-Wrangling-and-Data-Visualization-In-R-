install_github("ujjwalkarn/xda")
library(xda)
data(iris)
head(iris)
numSummary(iris)
charSummary(iris)
bivariate(iris,'Species','Sepal.Length')
Plot(iris,'Petal.Length')
library(xda)
data(iris)
head(iris)
numSummary(iris)
summary(iris)
charSummary(iris)
bivariate(iris,'Species','Sepal.Length')
Plot(iris,'Petal.Length') #plot petal.lnegth with other numerical
install.packages("keras")
library(keras)
mnist <- dataset_mnist()
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
library(rgbif)
occ_count(basisOfRecord='OBSERVATION')
occ_count(taxonKey=2435099, georeferenced=TRUE)
head(name_lookup(query = 'Helianthus annuus', rank="species", return = 'data'))
head(name_lookup(query = 'Helianthus annuus', rank="species", return = 'data',georeferenced=TRUE))
dataset_suggest(query="Amazon", type="OCCURRENCE")
key =name_backbone(name='Puma concolor')$speciesKey
dat <- occ_search(taxonKey=key, return='data', limit=100)
dat
gbifmap(dat)
key =name_backbone(name='hornbill')$speciesKey
dat <- occ_search(taxonKey=key, return='data', limit=100)
dat
gbifmap(dat)
key =name_backbone(name='Bucerotidae')$speciesKey
dat <- occ_search(taxonKey=key, return='data', limit=100)
dat
gbifmap(dat)
key =name_backbone(name='Buceros rhinoceros')$speciesKey
dat <- occ_search(taxonKey=key, return='data', limit=100)
dat <- occ_search(taxonKey=key, return='data', limit=1000)
dat
gbifmap(dat)
splist <- c('Anorrhinus galeritus', 'Anthracoceros albirostris',
'Anthracoceros malayanus','Buceros bicornis','Buceros rhinoceros',
'Rhinoplax vigil','Berenicornis comatus','Aceros corrugatus',
'Rhyticeros subruficollis','Rhyticeros undulatus')
keys <- vapply(splist, function(x) name_suggest(x)$key[1], numeric(1),
USE.NAMES=FALSE)
dat <- occ_data(keys, limit = 50)
library("data.table")
dd <- rbindlist(lapply(dat, function(z) z$data), fill = TRUE,
use.names = TRUE)
gbifmap(dd)
head(dd)
str(dd)
occ_count(taxonKey=2476004, georeferenced=TRUE)
head(name_lookup(query = 'Buceros rhinoceros', rank="species", return = 'data'))
my_code <- isocodes[grep("MY", isocodes$name), "code"]
occ_count(country=my_code)
my_code <- isocodes[grep("Malaysia", isocodes$name), "code"]
occ_count(country=my_code)
head(name_lookup(query='Bucerotiformes', rank="order", return="data"))
write.csv(dd,"F:\\SDM_in R\\hb1.csv")
occ_count(basisOfRecord='OBSERVATION')
library(rgbif)
occ_count(basisOfRecord='OBSERVATION')
occ_count(taxonKey=2476004, georeferenced=TRUE)
head(name_lookup(query='Bucerotiformes', rank="order", return="data"))
head(name_lookup(query = 'Buceros rhinoceros', rank="species", return = 'data'))
my_code <- isocodes[grep("Malaysia", isocodes$name), "code"]
occ_count(country=my_code)
dataset_suggest(query="Amazon", type="OCCURRENCE")
key =name_backbone(name='Buceros rhinoceros')$speciesKey
dat <- occ_search(taxonKey=key, return='data', limit=1000)
dat
gbifmap(dat) #removes nas and plots the geolocations
splist <- c('Anorrhinus galeritus', 'Anthracoceros albirostris',
'Anthracoceros malayanus','Buceros bicornis','Buceros rhinoceros',
'Rhinoplax vigil','Berenicornis comatus','Aceros corrugatus',
'Rhyticeros subruficollis','Rhyticeros undulatus')
keys <- vapply(splist, function(x) name_suggest(x)$key[1], numeric(1),
USE.NAMES=FALSE)
dat <- occ_data(keys, limit = 50)
library("data.table")
dd <- rbindlist(lapply(dat, function(z) z$data), fill = TRUE,
use.names = TRUE)
gbifmap(dd)
head(dd)
install.packages("tensorflow")
library(tensorflow)
install_tensorflow()
install_tensorflow()
install_tensorflow()
install_tensorflow()
library(tensorflow)
install_tensorflow()
install.packages("tensorflow")
install.packages("forecast")
library(forecast)
install.packages("tibbletime")
install.packages("ggplot2")
install.packages("tidyverse")
install.packages("caret")
install.packages("e1071")
install.packages("frbs")
install.packages("sets")
install.packages("fugeR")
install.packages("fuzzyFDR")
install.packages("dplyr")
install.packages("spocc")
library(spocc)
results = occ(query = 'Rhinoplax vigil', from = 'gbif')
results
head(results$gbif)
results = occ(query = 'Rhinoplax vigil', from = c('ebird', 'gbif'))
results = occ(query = 'Rhinoplax vigil', from = c('ebird', 'gbif','ecoengine'))
summary(results)
results = occ(query = 'Rhinoplax vigil', from = 'gbif',gbifopts = list(georeferenced = TRUE)))
spp= c("Rhinoplax vigil", "Buceros rhinoceros", "Anthracoceros malayanus")
res_set = occ(spp, from = c('gbif', 'ecoengine'))
head(res_set)
dat = occ(query = spp, from = "gbif", gbifopts = list(georeferenced = TRUE))
head(dat)
data = occ2df(dat)
mapleaflet(data = data, dest = ".")
install.packages("leaflet")
library(leaflet)
mapleaflet(data = data, dest = ".")
head(data)
data = occ2df(res_set)
head(data)
tail(data)
spp <- c("Danaus plexippus", "Accipiter striatus", "Pinus contorta")
dat <- occ(query = spp, from = "gbif", gbifopts = list(georeferenced = TRUE))
data <- occ2df(dat)
mapleaflet(data = data, dest = ".")
spp= c("Rhinoplax vigil", "Buceros rhinoceros", "Anthracoceros malayanus")
dat <- occ(query = spp, from = 'gbif', gbifopts = list(hasCoordinate=TRUE))
dat <- occ(query = spp, from = c('gbif', 'ecoengine'), gbifopts = list(hasCoordinate=TRUE))
head(data)
dat = occ(query = spp, from ='gbif', gbifopts = list(hasCoordinate=TRUE))
data = occ2df(dat)#convert to data frame
head(data)
library(ggplot2)
mapggplot(dat)
plot(dat, cex = 1, pch = 10)
names(data)
install.packages("TSA")
library(TSA)
library(spocc)
results = occ(query = 'Rhinoplax vigil', from = 'gbif')
results
head(results$gbif)
results = occ(query = 'Rhinoplax vigil', from = c('ebird', 'gbif','ecoengine'))
summary(results)
spp= c("Rhinoplax vigil", "Buceros rhinoceros", "Anthracoceros malayanus")
res_set = occ(spp, from = c('gbif', 'ecoengine'))
head(res_set)
dat = occ(query = spp, from ='gbif', gbifopts = list(hasCoordinate=TRUE))
data = occ2df(dat)#convert to data frame
head(data)
tail(data)
install.packages("rWBclimate")
library(rWBclimate)
library(spocc)
library(taxize)
Soug<-gbif("Sorex", "ugyunak", geo=T, removeZeros=T, args=c('originisocountrycode=US', 'originisocountrycode=CA')) #retrieve all occurrences of Sorex ugyunak from the U.S. and Canada
library(rgbif)
Soug<-gbif("Sorex", "ugyunak", geo=T, removeZeros=T, args=c('originisocountrycode=US', 'originisocountrycode=CA')) #retrieve all occurrences of Sorex ugyunak from the U.S. and Canada
key =name_backbone(name='Buceros rhinoceros')$speciesKey
dat <- occ_search(taxonKey=key, return='data', limit=1000)
dat
coordinates(dat) = c("decimalLongitude", "decimalLatitude") #Set coordinates to a Spatial data frame
library(dismo)
library(maptools)
coordinates(dat) = c("decimalLongitude", "decimalLatitude") #Set coordinates to a Spatial data frame
data(wrld_simpl)
plot(wrld_simpl, axes=TRUE, col='light green', las=1) #plot points on a world map
points(dat, col='orange', pch=20, cex=0.75)
zoom(wrld_simpl, axes=TRUE, las=1, col='light green') #zoom to a specific region
library(spocc)
spp= c("Rhinoplax vigil", "Buceros rhinoceros", "Anthracoceros malayanus")
dat = occ(query = spp, from ='gbif', gbifopts = list(hasCoordinate=TRUE))
install.packages("mapr")
library(mapr)
map_leaflet(dat)
dat = fixnames(dat)
map_gist(dat, color = c("#976AAE","#6B944D","#BD5945"))
library(spocc)
spp= c("Rhinoplax vigil", "Buceros rhinoceros", "Anthracoceros malayanus")
dat = occ(query = spp, from ='gbif', gbifopts = list(hasCoordinate=TRUE))
library(mapr)
map_leaflet(dat) #leaflet based interactive map
library(ggplot2)
map_ggmap(dat)
install.packages("ggmap")
library(ggmap)
map_ggmap(dat)
map_ggplot(dat, "malaysia")
map_plot(dat, cex = 1, pch = 10)
dat
map_leaflet(dat) #leaflet based interactive map
map_ggmap(dat) ##ggmap version
install.packages("NicheMapR")
install.packages("rJava")
install.packages("enfa")
library(maptools)
data(wrld_simpl)
file <- paste(system.file(package="dismo"), "/ex/bradypus.csv", sep="")
bradypus <- read.table(file, header=TRUE, sep=',')
plot(predictors, 1)
library(rJava)
install.packages("rJava")
library(rJava)
install.packages(c("NLP", "openNLP", "RWeka", "qdap"))
install.packages("openNLPmodels.en",
repos = "http://datacube.wu.ac.at/",
type = "source")
library(NLP)
library(openNLP)
library(RWeka)
install.packages("stringr", dependencies = TRUE)
setwd("F:\\SDM_in R\\Data\\1_Raster data\bioclim_land")
pa=read.csv("Pres_abs.csv")
setwd("F:\\SDM_in R\\Data\\1_Raster data\bioclim_land")
library(rvest)
url <- "https://en.wikipedia.org/wiki/2016_Summer_Olympics_medal_table"
medal_tally <- url %>% read_html() %>% html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>% html_table(fill=TRUE)
medal_tally <- medal_tally[[1]]
head(medal_tally)
%>% html_table(fill=TRUE)
medal_tally <- url %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>% html_table(fill=TRUE)
medal_tally <- url %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[3]') %>% html_table(fill=TRUE)
medal_tally <- medal_tally[[1]]
head(medal_tally)
medal_tally <- url %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>% html_table(fill=TRUE)
medal_tally <- medal_tally[[2]]
medal_tally <- medal_tally[[1]]
head(medal_tally)
url2="https://en.wikipedia.org/wiki/List_of_World_Heritage_Sites_in_the_United_Kingdom_and_the_British_Overseas_Territories"
whsuk <- url2 %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[3]') %>% html_table(fill=TRUE)
whsuk <- whsuk[[1]]
head(whsuk)
url3="https://en.wikipedia.org/wiki/North_Korea_at_the_Olympics"
nko <- url %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/div[4]/table/tbody/tr/td[1]/table') %>% html_table(fill=TRUE)
nko=nko[[1]]
nko <- nko[[1]]
medal_tally <- url %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[2]') %>% html_table(fill=TRUE)
medal_tally <- medal_tally[[1]]
head(medal_tally)
whsuk <- url2 %>% read_html() %>%
html_nodes(xpath='//*[@id="mw-content-text"]/div/table[3]') %>% html_table(fill=TRUE)
whsuk <- whsuk[[1]]
head(whsuk)
library(mclust)
require(fclust)
data(unemployment)
head(unemployment)
head(unemployment)
df = scale(unemployment)
head(df)
d = dist(df, method = "euclidean")
library(cluster)
hc1 = hclust(d, method = "complete" )
plot(hc1, cex = 0.6, hang = -1)
hc2 = agnes(df, method = "complete")
hc2$ac
hc3 = agnes(df, method = "ward")
pltree(hc3, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
hc4 = diana(df)
hc4$dc
pltree(hc4, cex = 0.6, hang = -1, main = "Dendrogram of diana")
hc5 <- hclust(d, method = "ward.D2" )
sub_grp <- cutree(hc5, k = 4) #work with 4 clusters
table(sub_grp)
library(tidyverse)
unemployment %>%mutate(cluster = sub_grp) %>%head
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
library(factoextra)
fviz_cluster(list(data = df, cluster = sub_grp))
library(fclust)
head(unemployment)
library(mclust)
require(fclust)
data(unemployment)
data(unemployment)
head(unemployment)
x=scale(unemployment) #to avoid bias
mc <- Mclust(x)            # Model-based-clustering
summary(mc)
mc$modelName                # Optimal selected model ==> "VVV"
mc$G                        # Optimal number of cluster => 3
head(mc$z)              # Probality to belong to a given cluster
head(mc$classification) # Cluster assignement of each observation
library(factoextra)
fviz_mclust(mc, "BIC", palette = "jco")
fviz_mclust(mc, "classification", geom = "point",
pointsize = 1.5, palette = "jco")
fviz_mclust(mc, "uncertainty", palette = "jco")
head(unemployment)
df = scale(unemployment)
head(df)
data(swiss)
head(swiss)
install.packages("FSelector")
library(FSelector)
head(titanic)
data("Titanic")
head(Titanic)
str(Titanic)
install.packages("ElemStatLearn")
data(iris)
result <- cfs(Species ~ ., iris)
f <- as.simple.formula(result, "Species")
f
subset <- cfs(Species~., iris)
f <- as.simple.formula(subset, "Species")
print(f)
library(mlbench)
install.packages("mlbench")
library(mlbench)
data(HouseVotes84)
head(HouseVotes84)
weights <- chi.squared(Class~., HouseVotes84)
print(weights)
head(SAheart)
library(ElemStatLearn)
head(SAheart)
subset <- cfs(chd~., SAheart)
f <- as.simple.formula(subset, "Species")
print(f)
weights <- chi.squared(chd~., SAheart)
print(weights)
library(fclust)
library(cluster)
head(unemployment)
df = scale(unemployment)
head(df)
d = dist(df, method = "euclidean")
head(d)
hc1 = hclust(d, method = "complete" )
plot(hc1, cex = 0.6, hang = -1)
hc2 = agnes(df, method = "complete")
plot(hc2, cex = 0.6, hang = -1)
hc2$ac
hc3 = agnes(df, method = "ward")
hc3$ac
pltree(hc3, cex = 0.6, hang = -1, main = "Dendrogram of agnes")
hc4 = diana(df)
hc4$dc
pltree(hc4, cex = 0.6, hang = -1, main = "Dendrogram of diana")
hc5 <- hclust(d, method = "ward.D2" )
sub_grp <- cutree(hc5, k = 4) #work with 4 clusters
table(sub_grp)
unemployment %>%mutate(cluster = sub_grp) %>%head
library(tidyverse)
unemployment %>%mutate(cluster = sub_grp) %>%head
plot(hc5, cex = 0.6)
rect.hclust(hc5, k = 4, border = 2:5)
library(factoextra)
fviz_cluster(list(data = df, cluster = sub_grp))
fviz_nbclust(df, FUN = hcut, method = "silhouette")
fviz_nbclust(df, FUN = hcut, method = "wss")
library(rattle)
data(swiss)
head(swiss)
x=scale(swiss)
myewkm = ewkm(x, 3, lambda=1, maxiter=100)
library(wskm)
myewkm = ewkm(x, 3, lambda=1, maxiter=100)
plot(x, col=myewkm$cluster)
plot(myewkm)
myewkm$cluster
myewkm$weights
rattle()
mc <- Mclust(x)            # Model-based-clustering
summary(mc)
mc$modelName                # Optimal selected model ==> "VVV"
mc$G                        # Optimal number of cluster => 3
setwd("F:\\DataMining_R\\3_LectureData\\section3")
stck=read.csv(5_stocks.csv)
stck=read.csv("5stocks.csv")
head(stck,n=10)
tail(stck,n=10)
ncol(stck)
smove=stck[,2:6]
head(smove)
smove=na.omit(smove)
head(smove)
myts = ts(smove, start=c(2001, 7), end=c(2017, 5), frequency=12)
plot(myts)
myts2 = window(myts, start=c(2014, 6), end=c(2014, 12))
plot(myts2)
library(xts)
library(xtsExtra)
plot.xts(stck, screens = factor(1, 1), auto.legend = TRUE)
plot.ts(myts2)
start(myts)
end(myts)
frequency(myts)
start(smove)
library(devtools)
install_github('sinhrks/ggfortify')
require(ggfortify)
autoplot(myts)
autoplot(myts, facets = FALSE)
library(xts)
autoplot(as.xts(myts), ts.colour = 'green')
install.packages("changepoint")
library(changepoint)
autoplot(cpt.meanvar(myts))
stck=read.csv("5stocks.csv") ## Montly data
head(stck,n=10)
tail(stck,n=10)
head(stck,n=10)
tail(stck,n=10)
smove=stck[,2:6]
head(smove)
smove=na.omit(smove)
head(stck,n=25)
head(stck,n=50)
myts = ts(smove, start=c(2001, 7), end=c(2017, 5), frequency=12)
plot(myts)
plot(myts)
start(myts)
end(myts)
frequency(myts)
myts2 = window(myts, start=c(2014, 6), end=c(2014, 12))
plot(myts2)
myts2 = window(myts, start=c(2014, 6), end=c(2017, 12))
myts2 = window(myts, start=c(2014, 6), end=c(2017, 4))
plot(myts2)
plot.ts(myts2)
autoplot(myts) # time series on facets
autoplot(myts, facets = FALSE) #time series of stocks on one plot
autoplot(as.xts(myts), ts.colour = 'green')
data("Groceries")
library(arules)
library(arulesViz)
library(datasets)
data("Groceries")
head(Groceries)
inspect(head(Groceries, 5))
inspect(Groceries[1:3])
inspect(Groceries[1:5])
size(head(Groceries))
class(Groceries)
size(head(Groceries))
itemFrequencyPlot(Groceries, topN=10, type="absolute", main="Item Frequency") # plot frequent items
groceryrules = apriori (Groceries, parameter = list(supp = 0.001, conf = 0.5)) # Min Support as 0.001, confidence as 0.8.
groceryrules = apriori (Groceries, parameter = list(supp = 0.001,
conf = 0.8)) # Min Support as 0.001, confidence as 0.8.
rules_conf = sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
rules_conf = sort (groceryrules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf)) # show the support, lift and confidence for all rules
rules_lift = sort (groceryrules, by="lift", decreasing=TRUE) # 'high-lift' rules.
inspect(head(rules_lift)) # show the support, lift and confidence for all rules
rules <- apriori(Groceries, parameter = list (supp = 0.001, conf = 0.6, maxlen=3))
rules = apriori (data=Groceries,
parameter=list (supp=0.001,conf = 0.08),
appearance = list (default="lhs",rhs="rice"),
control = list (verbose=F))
rules_conf = sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
rules = apriori (data=Groceries,
parameter=list (supp=0.001,conf = 0.20,minlen=2),
appearance = list(default="rhs",lhs="rice"),
control = list (verbose=F))
rules_conf = sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
data("Groceries")
class(Groceries)
inspect(head(Groceries, 5))
size(head(Groceries))
groceryrules = apriori (Groceries, parameter = list(supp = 0.001,
conf = 0.8)) # Min Support as 0.001, confidence as 0.8.
rules_conf = sort (groceryrules, by="confidence", decreasing=TRUE)
inspect(head(rules_conf)) # show the support, lift and confidence for all rules
rules_lift = sort (groceryrules, by="lift", decreasing=TRUE) # 'high-lift' rules.
inspect(head(rules_lift)) # show the support, lift and confidence for all rules
rules = apriori (data=Groceries,
parameter=list (supp=0.001,conf = 0.08),
appearance = list (default="lhs",rhs="rice"),
control = list (verbose=F))
rules_conf = sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
rules = apriori (data=Groceries,
parameter=list (supp=0.001,conf = 0.20,minlen=2),
appearance = list(default="rhs",lhs="rice"),
control = list (verbose=F))
rules_conf = sort (rules, by="confidence", decreasing=TRUE) # 'high-confidence' rules.
inspect(head(rules_conf))
head(AirPassengers)
str(AirPassengers)
head(EuStockMarkets)
class(EuStockMarkets)
class(myts)
decomposedRes <- decompose(myts type="mult")
decomposedRes <- decompose(myts, type="mult")
plot (decomposedRes)
acfRes <- acf(AirPassengers)
acfRes <- acf(myts)
